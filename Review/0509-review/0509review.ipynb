{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Activation Function(활성화 함수)\n",
        "* 활성화되는 조건을 따지는 함수.\\\n",
        "전기적 신호와 가중치가 모두 더해져 활성화가 될 때 사용되는 함수를 의미한다.\n",
        "1. Step Function(계단 함수) : 0~0.99까지 아무 신호도 출력되지 않다가 1이 되었을 때 신호 출력, 신호가 극단적으로 출력되는 변별력을 가지고 있다.\\\n",
        "평상시에는 거의 사용을 안하는 방식.\n",
        "2. Sigmoid Function : 이진분류(Binary Classfication)에 주로 사용, 마지막 출력층의 활성화 함수로 사용된다.\\\n",
        "x값이 0 근처를 기반으로 올라간다.\\\n",
        "y축 = '시그모이드를 통과한 x값'이 출력된다.\n",
        "        sigmoid function을 신경망 중간층에 사용하게 되면 중간에 값이 넘어가지 않다가 갑자기 넘어가는 현상이 발생함.\n",
        "        결과를 분명하게 만들어주는 점은 이 함수의 장점이지만 중간층에 사용하게되면 본 데이터가 망가질 수 있기 때문에 중간층에 사용하지 않음.\n",
        "3. ReLU(Rectified Linear Unit) : 0을 기점으로 0 아래쪽은 0, 0이 넘어가는 값은 그대로 출력, 마이너스값이 필요 없을 때 사용하고, 가장 많이 쓰이는 함수 중 하나이다.\n",
        "4. 항등 함수(Identity Function) : 입력된 값 그대로 출력하는 함수, 값이 왜곡되면 안되는 회귀(Regression) 문제에서 주로 사용된다.\n",
        "5. Softmax : 다중 클래스 분류(Multi Class Classfication)에 사용\\\n",
        "ex) 사람들의 행동에 따른 성격분류\n",
        "  - 입력값의 영향을 크게 받고, 입력값이 크면 출력값도 커진다.\n",
        "  - 출력값의 총합은 1이다.\n",
        "6. LeakyReLU : ReLU와 다르게 0 아래 값들의 특성을 조금이라도 확실하게 나타내기 위해 사용\n",
        "7. ELU(Exponential Linear Units) : 0 부분에서 값이 조금 완만하게 올라가는 형태의 그래프가 나타난다.\n",
        "\n",
        "### ※ 활성화 함수 일반적 사용 순서\n",
        "ELU -> LeakyReLU -> ReLU -> tanh -> sigmoid 순\n",
        "### ※ 스탠포드 강의에서 언급한 사용 순서\n",
        "ReLU -> ReLU Family(LeakyReLU, ELU) -> Sigmoid 사용X\n",
        "\n",
        "---\n",
        "   "
      ],
      "metadata": {
        "id": "Uey3WDW7mowW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Keras\n",
        "* CPU나 GPU를 사용하기 용이해졌다.\n",
        "- AI 접근성과 민주화(특정 계층의 것을 일반 사람들에게 나누어주는 의미)\n",
        "- 딥러닝의 대중화\n",
        "- 파이썬으로 구현된 high-level 딥러닝 API(추상화 수준이 높다)\n",
        "      * 추상화 수준\n",
        "      ex) 하늘에서 눈이 오는데 어쩌구(낮음)->함박눈(높음)\n",
        "- TensorFlow, Theano, CNTK(=>MS Cognitive tool kit)\n",
        "    - 원래 Keras의 구현은 이런 프레임워크들 위에 구현이 되었는데, 코딩은 바뀌지 않은 상태에서 내가 원하는 프레임워크를 선택해 구현하는 방식이었음\n",
        "    - 지금은 거의 Keras와 Tensorflow 두가지를 많이 사용하는 추세다.\n",
        "* Deep Learning의 구조\n",
        "  - Layer 단위로 작업한다.\n",
        "* 입력값에 대한 예측값이 잘 나오려면 가중치가 잘 설정되어있어야한다.\n",
        "  - 가중치의 정확한 값을 찾아내는 것이 딥러닝의 기본적인 목표\n",
        "* 예측데이터와 원본데이터를 비교해주는 함수를 손실함수라고 한다.\n",
        "  - Loss Function(손실 함수)를 통해 손실 점수를 알 수 있고 손실 점수를 줄이기 위해서 여러 방법이 있음.\n",
        "* 이름이 여러가지(다 같은 말)\n",
        "  - Cost Function\n",
        "  - Loss Function(대표적으로 사용)\n",
        "  - Error Function\n",
        "  - Objective Function\n",
        "\n",
        "### Binary Crossentropy\n",
        "* 둘 중 하나를 선택할 때\n",
        "\n",
        "### Categorical Crossentropy\n",
        "* 여러 개 중 하나를 선택할 때\n",
        "\n",
        "#### 역전파(Backpropagation)\n",
        "* 손실점수를 통해 다시 가중치를 역으로 설정해나가는 과정\n",
        "\n",
        "### Optimizer\n",
        "* 손실 함수에서 나온 차이만큼 가중치를 조절(업데이트) 하는 역할\n",
        "손실 점수를 최대한 줄일 때까지 반복하여 훈련한다.\n",
        "\n",
        "* Overfitting : 한 데이터를 반복학습할수록 그 데이터에만 맞는 가중치를 갖게되어\n",
        "새로운 데이터가 입력되었을 때 모델의 정확도가 떨어지게 된다.\n",
        "\n",
        "* Underfitting : 학습횟수가 너무 적어 발생하는 현상\n",
        "\n",
        "※ Over/Under fitting 현상이 발생하지 않도록 학습횟수를 조정하며 적절한 가중치와 손실점수, 정확도를 맞춰 최적의 모델을 찾아내는 것이 중요하다.\n",
        "\n",
        "### 경사하강법\n",
        "* Gradient Descent : 모든 자료를 다 검토, 속도가 느림\n",
        "* SGD(Stochastic Gradient Descent) : 일반적인 경사하강법은 정직하게 값에 접근하지만 SGD는 끊어서 접근하여 값에 접근했다가 벗어났다가를 반복하여 답을 찾음.\n",
        "* Momentum : 스텝 계산하여 움직인 후 관성에 따라 가는 법\n",
        "* Adagrad : 안가본곳은 빠르게, 값에 가까워질수록 보폭을 줄여 세밀히 탐색\n",
        "* AdaDelta : 보폭을 줄이다 멈추는 경우를 막기 위해 수정한 알고리즘 적용\n",
        "* RMSProp : 맥락을 봐가며 보폭을 줄이기\n",
        "* Adam : RMSProp + Momentum\n"
      ],
      "metadata": {
        "id": "oxcqtL4lyiSo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o0T6wwjWytIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wMGiDg87yteR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jTeryAamytk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pbfdwO9-ytqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dbcx9zWcytwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cz0o60jLyt1l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}