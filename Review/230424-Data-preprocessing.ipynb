{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO0gHgTC953PEfhOPxSjS6a"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 텍스트 마이닝(개념)\n","\n","* 사람들에 대한 정보는 대부분 텍스트, 사람의 말을 분석\n","- 인터넷의 대부분의 데이터는 말\n","- 감정분석\n","- 전체 문장중 중요한 단어 뽑아내기\n","- 단어가 긍정적인지 부정적인지 자동 리뷰작성, 자동 해시태그\n","- 인터넷, 책... 등의 데이터를 크롤링해서 데이터셋\n","  - GPT = 거대 언어 모델 이름 중의 하나\n","  - 페이스북, 구글 등도 거대 언어 모델을 소유하고있음.\n","  - 국내에선 네이버가 하이퍼클로바 라는 사업 진행\n","---\n","## 텍스트 데이터 전처리\n","### - Transform \n","* Lowercase : 대문자를 소문자로 \n","- Remove accents : 악센트 제거\n","- Parse html : html 태그 인식 여부\n","- Remove urls\n","\n","### - Tokenization\n","<strong>자연스럽게 이해할수 있는 단위로 쪼개는 방식</strong>\n","- Word Punctuation \n","- Whitespace\n","- Sentence \n","- Regexp : 정규식\n","  - 패턴 ex) [a-z]+ : a~z까지의 알파벳을 사용하여 뽑아내겠다\n","- Tweet\n","- stopwords를 통해 불필요한 단어들을 제외시킬수 있음.\n","---\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"2elpD2LCkB4d"}},{"cell_type":"markdown","source":["## Bag of words\n","* 자연어를 쉽고 단순하게 처리하는 간단한 방법\n","  - 문장을 통째로 수치화시켜 학습시키는건 어렵기 때문에 심플하게 처리하는 방법\n","  - 단어마다 고유번호를 등록\n","  - 문장에 있는 단어의 출현빈도를 보여주는 방법.\n","\n","  ※ Nomogram : 각각 단어들의 가중치를 보여주는 시각화 모델\n","---\n","\n","\n"],"metadata":{"id":"7Txe6GVxzEOT"}},{"cell_type":"markdown","source":["# 데이터 전처리\n","\n","## 1. Scaling\n","### 왜 해야 할까요?\n","* 변수의 크기가 너무 작거나, 너무 큰 경우 해당 변수가 Target 에 미치는 영향력이 제대로 표현되지 않을 수 있다.\n","---    \n","### Min-Max Scaling\n","* Min-Max 스케일링을 하면, 값의 범위가 0 ~ 1 사이로 변경된다. 최솟값과 최댓값을 맞춰 데이터 간 비교를 좀 수월하게 할 수 있음.\n","---\n","### Standard Scaling\n","* z-score라고 하는 데이터를 통계적으로 표준정규분포화 시켜 스케일링하는 방식.\n","* 데이터의 평균이 0, 표준 편차가 1이 되도록 스케일링.\n","  - 중심이 되는 데이터(평균 데이터)를 0, 최저 데이터 -1, 최고 데이터를 1로 하고 데이터의 분산도를 파악할수 있다.\n","- sklearn에서 preprocessing 패키지에 있음."],"metadata":{"id":"KLKI-QRunHTo"}},{"cell_type":"markdown","source":["## 2. Sampling\n","* 왜 함?\n","  - 클래스 불균형 문제는 분류를 목적으로하는 데이터셋에 클래스 라벨의 비율이 균형을 맞추지 않고, 한쪽으로 치우친 경우를 말함.\n","  - 이럴 경우 모델이 각 클래스의 데이터를 제대로 학습하기 어려워지기 때문에 각 클래스 간 균형을 맞추는 작업이 필요하다.\n","\n","* 1) Oversampling : 적은 클래스의 데이터 개수를 증가\n","* 2) Undersampling : 많은 클래스의 데이터 개수를 감소"],"metadata":{"id":"qYQFau8Po_9i"}},{"cell_type":"markdown","source":["## 3. 차원 축소(Dimensionality Redution)\n","\n","* 차원의 저주 : 저차원에서 일어나지 않는 현상들이 고차원에서 데이터를 분석하거나 다룰 때 생겨나는 현상을 말한다.\n","- 데이터 차원이 너무 큰 경우 필요없는 변수를 제거하고, 과적합을 방지하기 위해 데이터의 차원을 축소한다.\n","- 또는, 사람이 인식할 수 있는 차원이 3차원이 최대이므로 데이터의 시각화를 위해서 차원을 축소하기도 한다.\n","\n","※ 데이터의 밀도를 높여서 학습의 효율을 높이는 것\n","\n","---\n","### 주 성분 분석(Principal Component Analysis, PCA)\n","* 대표적 차원 축소 기법\n","- 여러 차원으로 이루어진 데이터를 가장 잘 표현하는 축(=분산을 잘 표현하는 축)으로 Projection 해서 차원을 축소하는 방식을 사용.\n","- 단점 : 떨어뜨린 주성분이 어떤 컬럼인지 설명할 수 없다\n","\n","#### 단계\n","1. 각 컬럼들의 값의 범위를 평균, 표준편차를 사용해 정규화시켜 동일하게 만들기(스케일링)\n","2. 데이터의 공분산 계산\n","3. 공분산 행렬에 대해 특이값 분해를 하여 주성분과 고유 값을 확인\n","4. 고유 값의 크기와 비율을 보고 몇개의 주성분을 선택할 것인지 or 원하는 차원의 개수만큼의 주성분 선택\n","5. 선택 주성분으로 모든 데이터를 Projection시켜 데이터의 차원 축소\n","---"],"metadata":{"id":"_oMa7avSpFeB"}},{"cell_type":"markdown","source":["## 4. Categorical Variable to Numeric Variable\n","* 범주형 변수를 수치형 변수로 나타내는 방법\n","  - 범주형 변수 = 차 등급을 나타내는 [소, 중, 대] 처럼 표현되는 변수를 말함.\n","  - 주로 데이터 상에서 문자열로 표현되는 경우가 많고, 문자와 숫자가 매핑되는 형태로 표현되기도 함.\n","\n","### 1) Label Encoding\n","* n개의 범주형 데이터를 0-n-1 의 연속적 수치 데이터로 표현\n","  - ex) 차 등급 변수를 라벨 인코딩으로 반환 시\n","    - 소형 : 0\n","    - 중형 : 1\n","    - 대형 : 2\n","  - 간단한 방법이지만, 범주형 데이터가 가지고있는 차이가 수치 차이라는 의미가 아니라는 것에 주의해야함.\n","\n","### 2) One-hot Encoding\n","* n개의 범주형 데이터를 n개의 비트(0,1) 벡터로 표현\n","  - ex) 차 등급 변수\n","    - 소형 : [1, 0, 0]\n","    - 중형 : [0, 1, 0]\n","    - 대형 : [0, 0, 1]\n","  - 서로 다른 범주에 대해서는 벡터 내적을 취했을 때 내적 값이 0이 나오게 되며, 서로 다른 범주 데이터는 독립적 관계라는 것을 표현할 수 있게 됨.\n","---"],"metadata":{"id":"WxgPfPpSsIdD"}},{"cell_type":"markdown","source":["# Make_Classfication 함수\n","<strong>make_classfication 함수는 설정에 따른 분류용 가상 데이터를 생성하는 명령어</strong>\n","### 인수와 반환값 모음\n","* n_samples : 표본 데이터 수, default 100\n","- n_features : 독립 변수의 수, default 20\n","- n_informative : 독립 변수 중 종속 변수와 상관 관계가 있는 성분의 수, default 2\n","- n_redundant : 독립 변수 중 다른 독립 변수의 선형 조합으로 나타나는 성분의 수, default 2\n","- n_repeated : 독립 변수 중 단순 중복 성분의 수, default 0\n","- n_classes : 종속 변수의 클래스 수, default 2\n","- n_clusters_per_class : 클래스 당 클러스터의 수, default 2\n","- weights : 각 클래스에 할당된 표본 수\n","- random_state : 난수 발생 시드\n","  - 반환값 : X : [n_samples, n_features] 크기의 배열\n","    - 독립 변수\n","  - y : [n_samples] 크기의 배열\n","    - 종속 변수\n","\n"],"metadata":{"id":"hXqo7gwbwE8v"}},{"cell_type":"markdown","source":["# scikit-learn\n","\n","* 오래됐지만 그만큼 결과가 예측 가능한 결과를 만들 수 있음.\n","- 알고리즘은 파이썬 클래스로 구현, 데이터셋은 Numpy 배열,\n","Pandas DataFrame, SciPy 희소행렬을 사용할 수 있다."],"metadata":{"id":"qfVwWjoUT1Vb"}}]}