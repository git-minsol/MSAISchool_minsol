{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMOMo0zoR5Jk55pFsk4Xv4H"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"be0Hfp2WAyxm"},"outputs":[],"source":["# 인터넷에서 데이터를 넘기는 방식은 2가지 : Get, Post\n","# 1. Get : 검색 후 나오는 주소 중간에 ?앞부분까지가 주소 부분이고\n","# 뒷부분은 데이터, 항목들을 전부 넘기고 있고 각각의 항목은 & 기호로 구분\n","# 이러한 방식은 get 방식으로 데이터를 넘긴다고 한다.\n","# 데이터의 길이에 제약, 보안성 부분에서 상대적으로 취약\n","# 2. Post : 아이디와 패스워드를 입력받아 인증 후 데이터를 처리하는 방법\n","# 데이터를 요청할 때 패킷 단위로 전달, 데이터 앞 부분에 헤더가 존재\n","# post방식은 패킷 단에 데이터를 숨겨서 전송\n","# 데이터 사이즈에 제약 없음.\n","\n","\n","\n","# Azure 에서 만든 리소스를 사용할 때 키와 엔드포인트 값을 사용한다.\n","# object detection : 주로 사진, 동영상은 YOLO.\n","# 사진이나 동영상 객체에서 대상을 트래킹하며 인식대상정보를 표시해주는 컴퓨팅비전 기술\n","# classfication : 구분\n","# Object Detection : 설명\n","\n","\n","# customvision.io\n","# custom vision은 학습되어있는 이미지가 없다.(=학습을 시켜줘야한다.)\n","# 이미지 업로드 -> 평가 -> 이상 없을 시 바로 사용\n","\n","# Restful : 웹사이트에서 url을 사용하여 클라이언트가 서버에 요청하면 서버가 클라이언트 측에 응답으로 반환하는 아키텍처 서비스\n","\n","# 안에 요소가 여러가지가 있을때 리스트 타입 구분(대괄호)을 한다.\n","# 클라우드 버전 :  CTP -> Preview(특정 사용자 대상으로 Close, 전체 대상으로 Open) -> GA\n","# 웹 브라우저에서 필요한 요소 : 주소, 헤더, 파라미터, 데이터(값이 없어도 형식을 지정해줘야한다.)\n","\n","# 이미지의 글자를 인식 : OCR\n","# 'unk' 코드를 쓰면 auto detect\n","# regions : 이미지 안의 글자가 있는 블럭 \n","# boundingbox : 이미지 안의 글자 각각의 단락이 있는 박스 \n","\n","\n","# 안면인식 기능도 있음(face detect api)\n","\n","\n","\n","# pip install 명령어(shell 명령어)를 통해 파이썬에 기본적으로 없는 패키지를 다운받아 사용할수있다.\n","# 참조되어있는 패키지도 한꺼번에 다운 받는다.\n","# 주피터노트북에서는 앞에 !를 붙여주는게 정석이긴 함.\n","# 인증 : 사람이 들어올수 있는지에 대한 여부 (key)\n","# 권한 : 들어와서 무엇을 할 수있는지에 대한 여부 (cridential)\n","\n","\n","# * 개와 고양이 사진을 MS Azure computer vision 리소스를 이용해\n","# 이미지 분석(image analysis)해보았던 결과물을 활용한 객체 검출(감지)(object detection) 실습\n","# Azure 계정 리소스 그룹에 computer vision 리소스를 만들고\n","# 리소스 접속을 위해 키값과 엔드포인트 주소를 복사하여 \n","# 헤더에는 키값, 파라미터에는 이미지의 특징을 표시, 데이터에는 이미지 주소를 url 형태로 입력\n","# 리소스에 포스트방식으로 데이터의 질의에대한 응답을 받는다.\n","# 결과값에는 분석결과 json데이터를 출력해주었고\n","# 결과값에서 원하는 분석특징을 빼오기 위해 result['분석특징'] 형태를 사용하였고\n","# json에 표시되는 분석특징 데이터들은 리스트 타입으로 표시되는 것을 확인할 수 있었다.\n","\n","# * 이미지 분석결과를 통해 객체 검출(감지)(object detection) 실습\n","# 먼저 주소를 생성 후 이미지 분석 때 했던 방식으로 리소스에 질의를 하였다.\n","# 이때는 detection 을 위해 detect_endpoint를 집어넣었고\n","# 결과값에는 json으로 데이터를 반환하게 하였다.\n","# 객체 검출 데이터에는 인식된 객체의 위치를 좌표형태로\n","# 객체의 인식결과가 딕셔너리 형식으로 표시되었다. \n","# 객체가 인식된 영역의 위치를 좌표 형태로 표시,\n","# 객체의 이름, 해당 객체가 인식된 이름에 얼마나 일치하는지에 대한 수치가 실수로 표시\n","# 이미지의 포맷정보, 모델의 버전이 표시가 되었다.\n","\n","# 또한 이 검출 데이터를 통해 이미지 위에 그림과 글을 쓰는 모듈인\n","# imageDraw, ImageFont를 이용하였고\n","# 이 둘은 PIL이라는 패키지 내에 있는 모듈이다.\n","# 이 두 모듈을 사용하기 위해서는\n","# 이미지를 메모리에서 풀어놓는 작업을 해야한다.\n","# 보통 이미지는 용량 압축작업이 되어있어 원래 이미지 사이즈보다 압축된 형태로 저장되어있기 때문에\n","# 메모리에 압축을 풀어 펼쳐놓고 그려야한다.\n","# 이 작업은 '변수명 = ImageDrqw.Draw(이미지변수명)' 형식으로 하였다.\n","# 이 두 모듈과 객체 검출 데이터를 통해\n","# 이미지 위에 객체 인식위치와 객체이름을 각각 그림, 글로 표시하였다.\n","# 인식 대상이 둘 이상일 때 반복문 for문을 사용하여 안에 있는 요소들의 반복횟수만큼\n","# 표시를 하게끔 만들어주고 객체검출데이터에 표시되었던 사각형 좌표명과 좌표값만 빼오게 하는 함수를 만들었고\n","# (좌표는 항상 튜플타입으로 표시해줘야한다.)\n","# 그 함수를 통해 검출결과값에서 좌표값만 반환할수있게 하였고 그 반환값을 통해 이미지 위에 그림과 글씨를 표현하였다.\n","\n","# *ocr은 글자 인식을 의미하는데 이미지에 위에 있는 글자들을 인식하여 텍스트로 변환해주는 모델이다.\n","# ocr도 위 두 모델과 마찬가지로 엔드포인트 주소와 키값을 통해 리소스에 포스트형식으로 질의하였고\n","# 응답값을 json형태로 반환하여 결과값을 출력하였다.\n","# ocr에서는 인식된 글자 하나 하나마다 박스 형태의 영역을 지정해 글자 하나, 단락 하나, 글자의 모양 등을\n","# 표시하였고 반복문 for문을 이용해 인식된 글자들을 표시해주었다.\n"]}]}